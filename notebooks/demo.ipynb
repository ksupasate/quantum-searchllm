{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TNAD Demo: Tensor Network-Augmented Decoding\n",
    "\n",
    "This notebook demonstrates the **Fidelity-Guided Beam Search (FGBS)** algorithm for improving logical coherence in LLM reasoning.\n",
    "\n",
    "## Overview\n",
    "\n",
    "TNAD uses quantum-inspired tensor networks to monitor and enforce structural coherence during text generation:\n",
    "- **MPS (Matrix Product State)**: Tensor network representation of token sequences\n",
    "- **CFS (Coherence Fidelity Score)**: Real-time coherence metric\n",
    "- **FGBS**: Beam search that balances LLM fluency with structural integrity\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TNAD package if not already installed\n",
    "# !pip install -e ..\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from tnad import FidelityGuidedBeamSearcher, MPSSequence, compute_cfs\n",
    "from tnad.utils import get_device\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding MPS and CFS\n",
    "\n",
    "First, let's understand how Matrix Product States work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an MPS with small bond dimension\n",
    "mps = MPSSequence(bond_dim=16, embedding_dim=64)\n",
    "\n",
    "# Add some random token embeddings\n",
    "cfs_values = []\n",
    "for i in range(20):\n",
    "    # Simulate token embedding\n",
    "    token_embedding = torch.randn(64)\n",
    "    mps.add_token(token_embedding)\n",
    "    \n",
    "    # Compute CFS\n",
    "    schmidt_values = mps.get_schmidt_values()\n",
    "    cfs = compute_cfs(schmidt_values)\n",
    "    cfs_values.append(cfs)\n",
    "\n",
    "# Visualize CFS evolution\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, len(cfs_values) + 1), cfs_values, marker='o', linewidth=2)\n",
    "plt.xlabel('Token Position', fontsize=12)\n",
    "plt.ylabel('Coherence Fidelity Score (CFS)', fontsize=12)\n",
    "plt.title('CFS Evolution as Tokens are Added', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=1, color='r', linestyle='--', label='Minimum Coherence', alpha=0.5)\n",
    "plt.axhline(y=16, color='g', linestyle='--', label='Maximum Coherence (χ=16)', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final MPS length: {mps.get_current_length()}\")\n",
    "print(f\"Final CFS: {cfs_values[-1]:.2f}\")\n",
    "print(f\"CFS range: [{min(cfs_values):.2f}, {max(cfs_values):.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading a Language Model\n",
    "\n",
    "Load a small model for demonstration (GPT-2 or a larger model if you have GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your model (uncomment one)\n",
    "# model_name = \"gpt2\"  # Small, runs on CPU\n",
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"  # Requires GPU and access approval\n",
    "# model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"  # Alternative\n",
    "\n",
    "print(f\"Loading model: {model_name}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16,  # Use float16 to save memory\n",
    "    device_map=\"auto\",  # Automatically place on available device\n",
    ")\n",
    "\n",
    "# Set padding token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "device = get_device()\n",
    "print(f\"✓ Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize FGBS Searcher\n",
    "\n",
    "Create the Fidelity-Guided Beam Search instance with chosen hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize FGBS\n",
    "searcher = FidelityGuidedBeamSearcher(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    beam_width=5,           # B = 5 parallel beams\n",
    "    alpha=0.5,              # Equal weight to fluency and coherence\n",
    "    bond_dim=16,            # χ = 16 (moderate logical bandwidth)\n",
    "    top_k=50,               # Consider top-50 tokens per beam\n",
    "    temperature=1.0,        # No temperature scaling\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(\"✓ FGBS Searcher initialized\")\n",
    "print(f\"  Beam width: {searcher.beam_width}\")\n",
    "print(f\"  Alpha (α): {searcher.alpha}\")\n",
    "print(f\"  Bond dimension (χ): {searcher.bond_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Example: Math Reasoning\n",
    "\n",
    "Test FGBS on a simple math problem requiring multi-step reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math problem\n",
    "prompt = \"\"\"Q: Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\n",
    "A: Let's think step by step.\"\"\"\n",
    "\n",
    "# Generate with FGBS\n",
    "print(\"Generating with FGBS...\")\n",
    "result = searcher.generate(\n",
    "    prompt,\n",
    "    max_length=200,\n",
    "    min_length=50,\n",
    "    return_details=True,\n",
    "    show_progress=True,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERATED SOLUTION:\")\n",
    "print(\"=\"*80)\n",
    "print(result['text'])\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Final Log Probability: {result['log_prob']:.2f}\")\n",
    "print(f\"Final Log CFS: {result['log_cfs']:.2f}\")\n",
    "print(f\"Final CFS: {np.exp(result['log_cfs']):.2f}\")\n",
    "print(f\"Composite Score: {result['composite_score']:.2f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Generation Dynamics\n",
    "\n",
    "Plot how coherence evolves during generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract trajectories\n",
    "cfs_trajectory = result['cfs_trajectory']\n",
    "score_trajectory = result['score_trajectory']\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot CFS trajectory\n",
    "axes[0].plot(cfs_trajectory, linewidth=2, color='#2E86AB')\n",
    "axes[0].set_xlabel('Generation Step', fontsize=12)\n",
    "axes[0].set_ylabel('Coherence Fidelity Score', fontsize=12)\n",
    "axes[0].set_title('CFS Evolution During Generation', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].axhline(y=1, color='red', linestyle='--', alpha=0.5, label='Min Coherence')\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot composite score trajectory\n",
    "axes[1].plot(score_trajectory, linewidth=2, color='#A23B72')\n",
    "axes[1].set_xlabel('Generation Step', fontsize=12)\n",
    "axes[1].set_ylabel('Composite Score', fontsize=12)\n",
    "axes[1].set_title('Composite Score (α·log P + (1-α)·log F)', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average CFS: {np.mean(cfs_trajectory):.2f}\")\n",
    "print(f\"CFS std dev: {np.std(cfs_trajectory):.2f}\")\n",
    "print(f\"Min CFS: {np.min(cfs_trajectory):.2f}\")\n",
    "print(f\"Max CFS: {np.max(cfs_trajectory):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare with Baseline\n",
    "\n",
    "Compare FGBS (α=0.5) with standard beam search (α=1.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple prompt for comparison\n",
    "compare_prompt = \"If A > B and B > C, then\"\n",
    "\n",
    "print(\"Running comparison...\")\n",
    "comparison = searcher.compare_with_baseline(\n",
    "    compare_prompt,\n",
    "    max_length=50,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FGBS OUTPUT (α=0.5):\")\n",
    "print(\"=\"*80)\n",
    "print(comparison['fgbs']['text'])\n",
    "print(f\"\\nFinal CFS: {np.exp(comparison['fgbs']['log_cfs']):.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BASELINE OUTPUT (Standard Beam Search, α=1.0):\")\n",
    "print(\"=\"*80)\n",
    "print(comparison['baseline']['text'])\n",
    "print(f\"\\nFinal CFS: {np.exp(comparison['baseline']['log_cfs']):.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON:\")\n",
    "print(\"=\"*80)\n",
    "cfs_comp = comparison['cfs_comparison']\n",
    "print(f\"FGBS CFS: {cfs_comp['fgbs_final_cfs']:.2f}\")\n",
    "print(f\"Baseline CFS: {cfs_comp['baseline_final_cfs']:.2f}\")\n",
    "print(f\"CFS Improvement: {cfs_comp['cfs_improvement']:.2f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Ablation Study: Effect of Alpha\n",
    "\n",
    "Test different α values to see the fluency-coherence trade-off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different alpha values\n",
    "alphas = [0.0, 0.3, 0.5, 0.7, 1.0]\n",
    "test_prompt = \"The logical conclusion is\"\n",
    "\n",
    "alpha_results = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    print(f\"\\nTesting α={alpha}...\")\n",
    "    \n",
    "    # Create searcher with specific alpha\n",
    "    test_searcher = FidelityGuidedBeamSearcher(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        beam_width=3,\n",
    "        alpha=alpha,\n",
    "        bond_dim=16,\n",
    "        device=device,\n",
    "    )\n",
    "    \n",
    "    # Generate\n",
    "    result = test_searcher.generate(\n",
    "        test_prompt,\n",
    "        max_length=40,\n",
    "        show_progress=False,\n",
    "    )\n",
    "    \n",
    "    alpha_results.append({\n",
    "        'alpha': alpha,\n",
    "        'text': result['text'],\n",
    "        'log_prob': result['log_prob'],\n",
    "        'cfs': np.exp(result['log_cfs']),\n",
    "    })\n",
    "\n",
    "# Visualize results\n",
    "alphas_list = [r['alpha'] for r in alpha_results]\n",
    "cfs_list = [r['cfs'] for r in alpha_results]\n",
    "logprob_list = [r['log_prob'] for r in alpha_results]\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot CFS\n",
    "color = '#2E86AB'\n",
    "ax1.set_xlabel('Alpha (α)', fontsize=12)\n",
    "ax1.set_ylabel('Coherence Fidelity Score', fontsize=12, color=color)\n",
    "ax1.plot(alphas_list, cfs_list, marker='o', linewidth=2, color=color, label='CFS')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot log probability on second y-axis\n",
    "ax2 = ax1.twinx()\n",
    "color = '#A23B72'\n",
    "ax2.set_ylabel('Log Probability', fontsize=12, color=color)\n",
    "ax2.plot(alphas_list, logprob_list, marker='s', linewidth=2, color=color, label='Log P')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.title('Effect of Alpha on Coherence vs Fluency', fontsize=14, fontweight='bold')\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALPHA ABLATION RESULTS:\")\n",
    "print(\"=\"*80)\n",
    "for r in alpha_results:\n",
    "    print(f\"\\nα={r['alpha']:.1f}: CFS={r['cfs']:.2f}, Log P={r['log_prob']:.2f}\")\n",
    "    print(f\"  Text: {r['text'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Custom Prompt Testing\n",
    "\n",
    "Try your own prompts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your custom prompt\n",
    "custom_prompt = \"\"\"Q: If all cats are mammals, and all mammals are animals, what can we conclude about cats?\n",
    "A: Let's reason step by step.\"\"\"\n",
    "\n",
    "# Generate\n",
    "custom_result = searcher.generate(\n",
    "    custom_prompt,\n",
    "    max_length=150,\n",
    "    return_details=True,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CUSTOM PROMPT RESULT:\")\n",
    "print(\"=\"*80)\n",
    "print(custom_result['text'])\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Final CFS: {np.exp(custom_result['log_cfs']):.2f}\")\n",
    "print(f\"Generation length: {len(custom_result['token_ids'])} tokens\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **MPS Construction**: How tensor networks represent token sequences\n",
    "2. **CFS Computation**: Real-time coherence monitoring\n",
    "3. **FGBS Generation**: Balancing fluency and structural integrity\n",
    "4. **Baseline Comparison**: Improvements over standard beam search\n",
    "5. **Ablation Studies**: Effect of hyperparameters (α)\n",
    "\n",
    "### Key Insights:\n",
    "- Higher CFS → more coherent reasoning\n",
    "- α=0.5 provides good balance between fluency and coherence\n",
    "- FGBS can improve logical consistency in multi-step reasoning\n",
    "\n",
    "### Next Steps:\n",
    "- Run full GSM8K benchmark: `python experiments/run_gsm8k.py`\n",
    "- Experiment with different models (Llama, Mistral, etc.)\n",
    "- Tune hyperparameters (χ, α, B) for your use case\n",
    "- Implement custom coherence metrics for your domain"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
