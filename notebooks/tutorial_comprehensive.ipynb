{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TNAD Complete Tutorial: From Basics to Advanced Usage\n",
    "\n",
    "This comprehensive tutorial covers:\n",
    "1. Understanding the core concepts (MPS, CFS, FGBS)\n",
    "2. Basic usage and examples\n",
    "3. Advanced hyperparameter tuning\n",
    "4. Performance optimization\n",
    "5. Custom use cases\n",
    "\n",
    "**Estimated time**: 30-45 minutes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Imports\n",
    "\n",
    "First, let's install and import all necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TNAD (if not already installed)\n",
    "# !pip install -e ..\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Dict\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from tnad import (\n",
    "    FidelityGuidedBeamSearcher,\n",
    "    MPSSequence,\n",
    "    compute_cfs,\n",
    "    compute_cfs_from_mps,\n",
    "    analyze_coherence_spectrum,\n",
    ")\n",
    "from tnad.utils import get_device\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"âœ“ All imports successful\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Understanding Matrix Product States (MPS)\n",
    "\n",
    "### What is an MPS?\n",
    "\n",
    "A Matrix Product State is a tensor network representation that captures correlations in sequences:\n",
    "\n",
    "```\n",
    "Token sequence: [\"The\", \"cat\", \"sat\", \"on\", \"mat\"]\n",
    "        â†“\n",
    "MPS chain: Aâ‚ â€” Aâ‚‚ â€” Aâ‚ƒ â€” Aâ‚„ â€” Aâ‚…\n",
    "           |    |    |    |    |\n",
    "         [The][cat][sat][on][mat]\n",
    "```\n",
    "\n",
    "Each tensor Aáµ¢ has shape `[Ï‡_left, d, Ï‡_right]` where:\n",
    "- **d**: Physical dimension (embedding dimension)\n",
    "- **Ï‡**: Bond dimension (controls entanglement capacity)\n",
    "\n",
    "Let's build an MPS step by step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an MPS with small dimensions for visualization\n",
    "mps = MPSSequence(\n",
    "    bond_dim=8,           # Ï‡ = 8 (small for demo)\n",
    "    embedding_dim=32,     # d = 32 (smaller than real LLM embeddings)\n",
    "    device='cpu',\n",
    "    normalize_embeddings=True,\n",
    ")\n",
    "\n",
    "print(f\"Created MPS: {mps}\")\n",
    "print(f\"Bond dimension (Ï‡): {mps.bond_dim}\")\n",
    "print(f\"Embedding dimension (d): {mps.embedding_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Tokens to MPS\n",
    "\n",
    "As we add tokens, the MPS grows and captures correlations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate adding 20 tokens (random embeddings for demonstration)\n",
    "cfs_values = []\n",
    "sequence_lengths = []\n",
    "\n",
    "for i in range(20):\n",
    "    # Simulate a token embedding (in practice, this comes from LLM)\n",
    "    token_embedding = torch.randn(32)\n",
    "    mps.add_token(token_embedding)\n",
    "    \n",
    "    # Compute Coherence Fidelity Score\n",
    "    if mps.get_current_length() > 1:\n",
    "        schmidt_values = mps.get_schmidt_values()\n",
    "        cfs = compute_cfs(schmidt_values)\n",
    "        cfs_values.append(cfs)\n",
    "        sequence_lengths.append(mps.get_current_length())\n",
    "\n",
    "print(f\"Final MPS length: {mps.get_current_length()}\")\n",
    "print(f\"Final CFS: {cfs_values[-1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CFS evolution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: CFS over time\n",
    "ax1.plot(sequence_lengths, cfs_values, marker='o', linewidth=2.5, markersize=8, color='#2E86AB')\n",
    "ax1.axhline(y=1, color='red', linestyle='--', alpha=0.5, label='Min Coherence')\n",
    "ax1.axhline(y=mps.bond_dim, color='green', linestyle='--', alpha=0.5, label=f'Max Coherence (Ï‡={mps.bond_dim})')\n",
    "ax1.set_xlabel('Sequence Length', fontsize=13, fontweight='bold')\n",
    "ax1.set_ylabel('Coherence Fidelity Score (CFS)', fontsize=13, fontweight='bold')\n",
    "ax1.set_title('CFS Evolution During Sequence Growth', fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: CFS distribution\n",
    "ax2.hist(cfs_values, bins=15, color='#A23B72', alpha=0.7, edgecolor='black')\n",
    "ax2.axvline(x=np.mean(cfs_values), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(cfs_values):.2f}')\n",
    "ax2.set_xlabel('Coherence Fidelity Score', fontsize=13, fontweight='bold')\n",
    "ax2.set_ylabel('Frequency', fontsize=13, fontweight='bold')\n",
    "ax2.set_title('CFS Distribution', fontsize=14, fontweight='bold')\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"CFS Statistics:\")\n",
    "print(f\"  Mean: {np.mean(cfs_values):.3f}\")\n",
    "print(f\"  Std:  {np.std(cfs_values):.3f}\")\n",
    "print(f\"  Range: [{np.min(cfs_values):.3f}, {np.max(cfs_values):.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Schmidt Values\n",
    "\n",
    "Schmidt values measure entanglement between prefix and suffix of a sequence. Let's visualize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Schmidt values at the middle cut\n",
    "schmidt_values = mps.get_schmidt_values()\n",
    "analysis = analyze_coherence_spectrum(schmidt_values)\n",
    "\n",
    "print(\"Schmidt Spectrum Analysis:\")\n",
    "print(f\"  CFS: {analysis['cfs']:.3f}\")\n",
    "print(f\"  Purity: {analysis['purity']:.4f}\")\n",
    "print(f\"  Effective Rank: {analysis['effective_rank']:.2f}/{analysis['bond_dim']}\")\n",
    "print(f\"  Entropy: {analysis['entropy']:.4f}\")\n",
    "print(f\"  Max Schmidt: {analysis['max_schmidt']:.4f}\")\n",
    "print(f\"  Uniformity: {analysis['uniformity']:.4f}\")\n",
    "\n",
    "# Visualize Schmidt spectrum\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(len(schmidt_values)), schmidt_values, color='#F18F01', edgecolor='black', alpha=0.8)\n",
    "plt.xlabel('Schmidt Index i', fontsize=13, fontweight='bold')\n",
    "plt.ylabel('Schmidt Value Î»áµ¢', fontsize=13, fontweight='bold')\n",
    "plt.title('Schmidt Spectrum (Entanglement Structure)', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Uniform spectrum â†’ High entanglement â†’ Coherent sequence\")\n",
    "print(\"- Peaked spectrum â†’ Low entanglement â†’ Decoherent sequence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Fidelity-Guided Beam Search (FGBS)\n",
    "\n",
    "Now let's use FGBS with a real language model. We'll start with a small model for quick demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your model (adjust based on your hardware)\n",
    "# Option 1: Small model (CPU-friendly)\n",
    "model_name = \"gpt2\"  \n",
    "\n",
    "# Option 2: Larger model (requires GPU and Hugging Face access)\n",
    "# model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "print(f\"Loading model: {model_name}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "    device_map=\"auto\" if torch.cuda.is_available() else None,\n",
    ")\n",
    "\n",
    "# Set padding token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "device = get_device()\n",
    "if not torch.cuda.is_available():\n",
    "    model = model.to(device)\n",
    "\n",
    "print(f\"âœ“ Model loaded on {device}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()) / 1e6:.1f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize FGBS Searcher\n",
    "\n",
    "Key hyperparameters:\n",
    "- **beam_width (B)**: Number of parallel hypotheses (5-10 typical)\n",
    "- **alpha (Î±)**: Fluency-coherence balance (0.5 = balanced)\n",
    "- **bond_dim (Ï‡)**: MPS entanglement capacity (16 typical)\n",
    "- **top_k**: Candidate tokens per beam (50 typical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize FGBS with default hyperparameters\n",
    "searcher = FidelityGuidedBeamSearcher(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    beam_width=5,           # B = 5 parallel beams\n",
    "    alpha=0.5,              # Î± = 0.5 (balanced)\n",
    "    bond_dim=16,            # Ï‡ = 16 (moderate logical bandwidth)\n",
    "    top_k=50,               # Consider top-50 tokens\n",
    "    temperature=1.0,        # No temperature scaling\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(\"âœ“ FGBS Searcher initialized\")\n",
    "print(f\"  Configuration: B={searcher.beam_width}, Î±={searcher.alpha}, Ï‡={searcher.bond_dim}\")\n",
    "print(f\"  Embedding dimension: {searcher.embedding_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Math Reasoning\n",
    "\n",
    "Test FGBS on a multi-step math problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math problem requiring step-by-step reasoning\n",
    "prompt_math = \"\"\"Q: Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\n",
    "A: Let's think step by step.\"\"\"\n",
    "\n",
    "print(\"Generating solution with FGBS...\\n\")\n",
    "result_math = searcher.generate(\n",
    "    prompt_math,\n",
    "    max_length=150,\n",
    "    min_length=30,\n",
    "    return_details=True,\n",
    "    show_progress=True,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GENERATED SOLUTION:\")\n",
    "print(\"=\"*80)\n",
    "print(result_math['text'])\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"METRICS:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Log Probability (Fluency): {result_math['log_prob']:.2f}\")\n",
    "print(f\"Log CFS (Coherence): {result_math['log_cfs']:.2f}\")\n",
    "print(f\"CFS (exponential): {np.exp(result_math['log_cfs']):.2f}\")\n",
    "print(f\"Composite Score: {result_math['composite_score']:.2f}\")\n",
    "print(f\"Generated tokens: {len(result_math['token_ids'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Generation Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract trajectories\n",
    "cfs_traj = result_math['cfs_trajectory']\n",
    "score_traj = result_math['score_trajectory']\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Plot 1: CFS trajectory\n",
    "axes[0, 0].plot(cfs_traj, linewidth=2.5, color='#2E86AB', marker='o', markersize=4)\n",
    "axes[0, 0].axhline(y=1, color='red', linestyle='--', alpha=0.5, label='Min Coherence')\n",
    "axes[0, 0].set_xlabel('Generation Step', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Coherence Fidelity Score', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_title('Coherence Evolution (CFS)', fontsize=13, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Composite score trajectory\n",
    "axes[0, 1].plot(score_traj, linewidth=2.5, color='#A23B72', marker='s', markersize=4)\n",
    "axes[0, 1].set_xlabel('Generation Step', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Composite Score', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_title('Composite Score (Î±Â·log P + (1-Î±)Â·log F)', fontsize=13, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: CFS histogram\n",
    "axes[1, 0].hist(cfs_traj, bins=20, color='#F18F01', alpha=0.7, edgecolor='black')\n",
    "axes[1, 0].axvline(x=np.mean(cfs_traj), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(cfs_traj):.2f}')\n",
    "axes[1, 0].set_xlabel('Coherence Fidelity Score', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_title('CFS Distribution', fontsize=13, fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 4: Rolling statistics\n",
    "window = 5\n",
    "rolling_mean = np.convolve(cfs_traj, np.ones(window)/window, mode='valid')\n",
    "axes[1, 1].plot(cfs_traj, alpha=0.3, color='gray', label='Raw CFS')\n",
    "axes[1, 1].plot(range(window-1, len(cfs_traj)), rolling_mean, linewidth=2.5, color='#006BA6', label=f'Rolling Mean (w={window})')\n",
    "axes[1, 1].set_xlabel('Generation Step', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('CFS', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_title('CFS with Rolling Average', fontsize=13, fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nStatistics:\")\n",
    "print(f\"  Average CFS: {np.mean(cfs_traj):.3f}\")\n",
    "print(f\"  CFS std dev: {np.std(cfs_traj):.3f}\")\n",
    "print(f\"  Min CFS: {np.min(cfs_traj):.3f}\")\n",
    "print(f\"  Max CFS: {np.max(cfs_traj):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Comparing FGBS with Baseline\n",
    "\n",
    "Let's compare FGBS (Î±=0.5) with standard beam search (Î±=1.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple logical reasoning prompt\n",
    "prompt_logic = \"If A > B and B > C, then\"\n",
    "\n",
    "print(\"Running comparison: FGBS vs Standard Beam Search\\n\")\n",
    "comparison = searcher.compare_with_baseline(\n",
    "    prompt_logic,\n",
    "    max_length=50,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FGBS OUTPUT (Î±=0.5 - Balanced):\")\n",
    "print(\"=\"*80)\n",
    "print(comparison['fgbs']['text'])\n",
    "print(f\"\\n  Final CFS: {np.exp(comparison['fgbs']['log_cfs']):.2f}\")\n",
    "print(f\"  Log Probability: {comparison['fgbs']['log_prob']:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BASELINE OUTPUT (Î±=1.0 - Pure LLM):\")\n",
    "print(\"=\"*80)\n",
    "print(comparison['baseline']['text'])\n",
    "print(f\"\\n  Final CFS: {np.exp(comparison['baseline']['log_cfs']):.2f}\")\n",
    "print(f\"  Log Probability: {comparison['baseline']['log_prob']:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"IMPROVEMENT:\")\n",
    "print(\"=\"*80)\n",
    "cfs_comp = comparison['cfs_comparison']\n",
    "print(f\"CFS Improvement: {cfs_comp['cfs_improvement']:.2f} ({cfs_comp['cfs_improvement']/cfs_comp['baseline_final_cfs']*100:.1f}%)\")\n",
    "print(f\"FGBS achieves {cfs_comp['fgbs_final_cfs']/cfs_comp['baseline_final_cfs']:.2f}x higher coherence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Hyperparameter Ablation Study\n",
    "\n",
    "### Effect of Alpha (Î±): Fluency-Coherence Tradeoff\n",
    "\n",
    "- Î± = 0: Pure coherence (may sacrifice fluency)\n",
    "- Î± = 0.5: Balanced (recommended)\n",
    "- Î± = 1: Pure LLM probability (standard beam search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different alpha values\n",
    "alphas = [0.0, 0.3, 0.5, 0.7, 1.0]\n",
    "test_prompt = \"The logical conclusion is\"\n",
    "\n",
    "alpha_results = []\n",
    "\n",
    "print(\"Running alpha ablation study...\\n\")\n",
    "for alpha in alphas:\n",
    "    print(f\"Testing Î±={alpha}...\")\n",
    "    \n",
    "    # Create searcher with specific alpha\n",
    "    test_searcher = FidelityGuidedBeamSearcher(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        beam_width=3,  # Smaller beam for speed\n",
    "        alpha=alpha,\n",
    "        bond_dim=16,\n",
    "        device=device,\n",
    "    )\n",
    "    \n",
    "    # Generate\n",
    "    result = test_searcher.generate(\n",
    "        test_prompt,\n",
    "        max_length=40,\n",
    "        show_progress=False,\n",
    "    )\n",
    "    \n",
    "    alpha_results.append({\n",
    "        'alpha': alpha,\n",
    "        'text': result['text'],\n",
    "        'log_prob': result['log_prob'],\n",
    "        'cfs': np.exp(result['log_cfs']),\n",
    "        'composite_score': result['composite_score'],\n",
    "    })\n",
    "\n",
    "print(\"\\nâœ“ Ablation study complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize alpha ablation results\n",
    "alphas_list = [r['alpha'] for r in alpha_results]\n",
    "cfs_list = [r['cfs'] for r in alpha_results]\n",
    "logprob_list = [r['log_prob'] for r in alpha_results]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Dual axis (CFS and Log Prob)\n",
    "color1 = '#2E86AB'\n",
    "ax1.plot(alphas_list, cfs_list, marker='o', linewidth=2.5, markersize=10, color=color1, label='CFS')\n",
    "ax1.set_xlabel('Alpha (Î±)', fontsize=13, fontweight='bold')\n",
    "ax1.set_ylabel('Coherence Fidelity Score', fontsize=13, fontweight='bold', color=color1)\n",
    "ax1.tick_params(axis='y', labelcolor=color1)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_title('Effect of Î± on Fluency vs Coherence', fontsize=14, fontweight='bold')\n",
    "\n",
    "ax1_twin = ax1.twinx()\n",
    "color2 = '#A23B72'\n",
    "ax1_twin.plot(alphas_list, logprob_list, marker='s', linewidth=2.5, markersize=10, color=color2, label='Log Prob')\n",
    "ax1_twin.set_ylabel('Log Probability', fontsize=13, fontweight='bold', color=color2)\n",
    "ax1_twin.tick_params(axis='y', labelcolor=color2)\n",
    "\n",
    "# Add legend\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax1_twin.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc='best', fontsize=11)\n",
    "\n",
    "# Plot 2: Composite score\n",
    "composite_list = [r['composite_score'] for r in alpha_results]\n",
    "ax2.plot(alphas_list, composite_list, marker='D', linewidth=2.5, markersize=10, color='#F18F01')\n",
    "ax2.set_xlabel('Alpha (Î±)', fontsize=13, fontweight='bold')\n",
    "ax2.set_ylabel('Composite Score', fontsize=13, fontweight='bold')\n",
    "ax2.set_title('Composite Score vs Alpha', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axvline(x=0.5, color='red', linestyle='--', alpha=0.5, label='Î±=0.5 (balanced)')\n",
    "ax2.legend(fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALPHA ABLATION RESULTS:\")\n",
    "print(\"=\"*80)\n",
    "for r in alpha_results:\n",
    "    print(f\"\\nÎ±={r['alpha']:.1f}:\")\n",
    "    print(f\"  CFS: {r['cfs']:.2f} | Log P: {r['log_prob']:.2f} | Composite: {r['composite_score']:.2f}\")\n",
    "    print(f\"  Text: {r['text'][:100]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY INSIGHTS:\")\n",
    "print(\"=\"*80)\n",
    "print(\"- Î±=0.0: Maximizes coherence, may sacrifice fluency\")\n",
    "print(\"- Î±=0.5: Balanced approach (recommended for most tasks)\")\n",
    "print(\"- Î±=1.0: Standard beam search (fluency only)\")\n",
    "print(\"\\nRecommendation: Use Î±=0.3-0.5 for reasoning tasks, Î±=0.6-0.7 for creative writing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Custom Prompts and Use Cases\n",
    "\n",
    "Now try your own prompts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom prompt - edit this!\n",
    "custom_prompt = \"\"\"Q: If all cats are mammals, and all mammals are animals, what can we conclude about cats?\n",
    "A: Let's reason step by step.\"\"\"\n",
    "\n",
    "# Generate\n",
    "custom_result = searcher.generate(\n",
    "    custom_prompt,\n",
    "    max_length=120,\n",
    "    return_details=True,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CUSTOM PROMPT RESULT:\")\n",
    "print(\"=\"*80)\n",
    "print(custom_result['text'])\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"METRICS:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Final CFS: {np.exp(custom_result['log_cfs']):.2f}\")\n",
    "print(f\"Generation length: {len(custom_result['token_ids'])} tokens\")\n",
    "print(f\"Average CFS: {np.mean(custom_result['cfs_trajectory']):.2f}\")\n",
    "print(f\"CFS stability (std): {np.std(custom_result['cfs_trajectory']):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Performance Tips and Best Practices\n",
    "\n",
    "### Hyperparameter Selection Guide\n",
    "\n",
    "| Use Case | Î± | Ï‡ | B | Notes |\n",
    "|----------|---|---|---|-------|\n",
    "| **Math reasoning** | 0.3-0.4 | 16-32 | 5-8 | Prioritize coherence |\n",
    "| **Logical reasoning** | 0.4-0.5 | 16 | 5 | Balanced |\n",
    "| **Creative writing** | 0.6-0.8 | 8-16 | 3-5 | Prioritize fluency |\n",
    "| **Fast generation** | 0.5 | 8 | 3 | Reduced complexity |\n",
    "| **High quality** | 0.4 | 32 | 8 | Maximum coherence tracking |\n",
    "\n",
    "### Memory Optimization\n",
    "\n",
    "```python\n",
    "# For long sequences or large models:\n",
    "import gc\n",
    "import torch\n",
    "\n",
    "# Clear cache periodically\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Use smaller bond dimension\n",
    "searcher = FidelityGuidedBeamSearcher(\n",
    "    ...,\n",
    "    bond_dim=8,  # Instead of 16\n",
    "    beam_width=3,  # Instead of 5\n",
    ")\n",
    "```\n",
    "\n",
    "### Debugging Tips\n",
    "\n",
    "```python\n",
    "# Enable detailed logging\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "# Inspect beam trajectories\n",
    "result = searcher.generate(prompt, return_details=True)\n",
    "all_beams = result['all_beams']\n",
    "for i, beam in enumerate(all_beams):\n",
    "    print(f\"Beam {i}: score={beam.composite_score:.3f}, \"\n",
    "          f\"cfs={np.exp(beam.log_cfs):.3f}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "### What We Covered\n",
    "\n",
    "1. âœ… **MPS fundamentals**: Tensor network representation of sequences\n",
    "2. âœ… **CFS computation**: Coherence monitoring through Schmidt values\n",
    "3. âœ… **FGBS algorithm**: Balancing fluency and coherence in generation\n",
    "4. âœ… **Hyperparameter tuning**: Effect of Î±, Ï‡, and B\n",
    "5. âœ… **Performance optimization**: Best practices for efficient generation\n",
    "\n",
    "### Further Resources\n",
    "\n",
    "- ðŸ“„ **[Paper]**: Read the full technical paper\n",
    "- ðŸ”¬ **[Experiments]**: Run GSM8K/StrategyQA benchmarks (`experiments/`)\n",
    "- ðŸ“Š **[Performance Notebook]**: Detailed profiling (`notebooks/performance_benchmark.ipynb`)\n",
    "- ðŸŽ® **[Colab Demo]**: Try on Google Colab (`notebooks/tnad_colab.ipynb`)\n",
    "\n",
    "### Citation\n",
    "\n",
    "If you use TNAD in your research:\n",
    "\n",
    "```bibtex\n",
    "@article{tnad2024,\n",
    "  title={TNAD: Tensor Network-Augmented Decoding for Coherent LLM Reasoning},\n",
    "  author={Your Name},\n",
    "  journal={arXiv preprint arXiv:2XXX.XXXXX},\n",
    "  year={2024}\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Questions or issues?** Open an issue on [GitHub](https://github.com/your-username/quantum-searchllm/issues)\n",
    "\n",
    "**Happy coherent generating! ðŸš€**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
